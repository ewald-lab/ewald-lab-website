{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Ewald Lab handbook!","text":"<p>This is a guide for conducting scientific research in the Ewald Lab. This is a living document; it will change as we identify new and better ways of doing things. It's purpose is to get all lab members on the same page, so that we have a shared understanding of both the big picture (ie. how to conduct a research project) and smaller day-to-day details (ie. lab meeting frequency and times) Resources that we do not have permission to share are private Google Drive links that can only be accessed by lab members.</p>"},{"location":"conducting-research/","title":"","text":"<p>As a computational researcher, it is easy to fill your days implementing many small ideas of how you could improve a given analysis. Without intentional and strategic planning, it's very difficult to ensure that months-to-years of this type of effort results in a coherent, high-impact paper.</p>"},{"location":"conducting-research/#1-choose-a-topic-that-people-care-about","title":"1. Choose a topic that people care about","text":"<p>If you were able to answer your research question, solve your engineering challenge, or predict something, would it matter? Who would be excited about it? Get external feedback - do other people really care about it, and think that it's an important problem to solve? If people aren't very exicited about it even assuming complete success, you should probably pivot.</p> <p>Once you've identified an important problem, do some literature searches. Are other people working on this problem or question, or on something similar? If yes, this isn't a bad thing - it's further evidence that this is a worthwhile research topic that is probably tractable with currently available data and tools. If the space is too crowded it can be difficult to differentiate yourself, so there is a balance here.</p>"},{"location":"conducting-research/#2-know-how-to-evaluate-success","title":"2. Know how to evaluate success","text":"<p>In research, 90% of ideas fail. Many computational researchers may feel that the conventional way of performing an analysis is deeply flawed, and that some alternative might be better. However, without a clear and quantitative metric of what \"better\" means, it will be difficult (or impossible) to evaluate whether the idea is a good one. If you have plans for how you will evaluate your hypothesis/performance, get feedback from others. Is your proposed metric biased in some way? Does it miss some important aspect of your problem?</p> <p>You should also have some idea of what level of performance is good enough to effectively solve your problem, or what level of improvement will be exciting to others.</p>"},{"location":"conducting-research/#3-critically-assess-the-available-data","title":"3. Critically assess the available data","text":"<p>Even if you have a great research question or machine learning task and a plan of how to measure success, you will still fail if the available data is not of an appropriate size and quality. You won't know exactly how much data you'll need before starting, but you can usually guess the order of magnitude based on the computational methods that you plan on using. For example, if you only have 100 samples worth of data, training a deep learning network from scratch is not going to work.</p> <p>Your set of computational options is usually tied to your data size and quality, especially the state of the metadata. Keep this in mind when learning about new technology that allows scientists to measure new types of data or existing types but at greater scale - maybe the new technology enables investigations that you'd previouly dropped due to lack of data.</p> <p>Also think creatively about how existing sources of data can be used for new things. Is there a large set of images or text that could be processed with deep learning to turn them into something structured and ML-ready? Usually we think about a project originating from a research question. However, sometimes a project starts by identifying a new source of data that no one is paying attention to and asking \"what types of novel analyses are possible with data of this scale\"? Being the first person to analyse a new source of data is the easiest way to boost the novelty of what you're doing.</p>"},{"location":"conducting-research/#4-stay-organised","title":"4. Stay organised","text":"<p>Keep your code organised and reproducible in a GitHub repository, from day one. You are strongly encouraged to use a NextFlow pipeline. While there's a bit of overhead to learn, it makes it easy to try out different pipelines in an organised way. If you are trying out many different ideas, keep track of what you did, when you did it, why you did it, and whether it improved things according to your metrics, or if you learned something concrete about your research topic. Use sensible file and directory names, and add more documentation than you think is neccessary - future you will be grateful!</p> <p>The best way to ensure that your code is organised and understandable is to collaborate with others. If you share your code, you will be embarrassed if its awful. Your collaborators will also give you feedback if something is confusing. See the GitHub Guidelines page for more technical recommendations on how to structure your analysis.</p>"},{"location":"conducting-research/#5-write-early-and-regularly","title":"5. Write early and regularly","text":"<p>Many new researchers think that research falls into two separate steps: 1) do the analysis, and 2) write up the results. This is nearly always false. When you write down the motivation for your work, the main objective, what you did, and what the results are, you often realise that you haven't asked the most important question or convincingly proved your main point, and that your analysis is only halfway done. Reviewing literature for the introduction or discussion may give you brilliant new ideas, or you may find that your idea isn't as novel as you thought. In all of these cases, it's better to find out as early as possible, when you still have the time and energy to backtrack, expand, or pivot your plans.</p> <p>When you summarise and communicate your progress to someone else, you are forced to re-examine how your latest days/weeks of effort relate to your original objectives. Writing regularly helps avoid feature/objective-creep, and keeps you focused on the most important things. Write a proposal before you start working, work on an outline as soon as you start generating results, and keep track of literature that could go in your introduction/discussion. Accept any opportunity to present your work to others - making a set of slides isn't the same as writing a paper draft, but it helps to organise your overall ideas.</p>"},{"location":"conducting-research/#6-wrap-things-up","title":"6. Wrap things up","text":"<p>There are always more ways to incrementally improve some aspect of your analysis. Sometimes, implementing more ideas will degrade the quality of your paper because there will be too many results to coherently pull together into a paper that others will enjoy reading. Once you've evaluated your main ideas and explored a few additional things that came up along the way, it is usually in your best interest to narrow your scope and finish the paper.</p> <p>Often computational researchers procrastinate writing their first draft because they enjoy coding more than writing, and the thought of using a point-and-click reference manager and word processor makes them shudder. Stop it! Start writing the first complete draft! It's going to take longer than you think, and you're going to feel very good when you're done.</p>"},{"location":"conducting-research/#final-thoughts","title":"Final thoughts","text":"<p>The more rigorous and critical you are during steps 1-4, the easier the writing process will be. It's really fun to write a paper on an important topic when you have clear, quantitative metrics that show success and an organised codebase that can reproduce all of your results with minimal effort. Trying to write a paper based on a disorganized set of scripts that produce 1000 figures and tables but do not correspond to a clear research objective is excrutiating.</p> <p>For these reasons, Ewald Lab members are expected to write very short research proposals (~1 page) on steps 1-3 and discuss them with the lab (and ideally others) BEFORE they start analysing any data. This will turn into the outline for your paper, which will turn into your first draft.</p> <p>It's also very easy to get lost down rabbit holes and obsess over small details that really don't matter very much to the big picture. Stacking multiple small improvements on top of each other can collectively make a significant improvement (see the AlphaFold papers), but this takes laser-sharp focus, discipline, and organisation. Clearly stating your task/objective, having quantitative metrics, and regularly commmunicating your progress to keep yourself accountable is essential to ensure that your many ideas build towards an impactful end product.</p>"},{"location":"courses-overview/","title":"Useful courses","text":"<p>This is a collection of online lectures and tutorials that members of the Ewald Lab have found helpful. </p>"},{"location":"courses-overview/#practical-cs-skills","title":"Practical CS Skills","text":"<ul> <li>Missing CS Semester</li> <li>Learn Git Branching</li> </ul>"},{"location":"courses-overview/#deep-learning","title":"Deep Learning","text":"<ul> <li>MIT Intro to Deep Learning</li> <li>Zero to Mastery Pytorch</li> <li>Interactive explainers for CNNs, transformers, and diffusion</li> </ul>"},{"location":"git-repo/","title":"","text":"<p>Writing open and reproducible code is an essential part of computational biology research. We adhere to a strict set of organisational and stylistic conventions to maximise code reuse by lab members, improve analysis rigour, and reduce the amount of code clean-up needed before paper submission. These standards are meant for general data analysis repositories that would accompany a publication, not for published software tools.</p>"},{"location":"git-repo/#initialising-a-new-repository","title":"Initialising a new repository","text":"<p>Create a new repository within the Ewald Lab GitHub Org with the following specs:</p> <ul> <li>Use the Ewald Lab analysis repo template</li> <li>If it's a project driven primarily by you, the repo name should be YEAR_MONTH_LASTNAME_SHORT_DESCRIPTION, for example 2025_08_Ewald_TimeDynamics</li> <li>If it's a large collaborative project, use the name of the collaboration instead of your name, for example 2025_08_OASIS_CellPainting</li> <li>Make sure the repository is set to Private; this can be changed to Public after discussion with all team members, or upon publication</li> <li>Add the ewald-lab team to the repo as collaborators with 'Write' permissions</li> <li>Add the ewald-lab-admin team to the repo as collaborators with 'Admin' permissions (this is just Jess for now)</li> <li>Set the license to CC0</li> <li>Make sure you include a .gitignore with the type set to the main programming language that you will use (likely Python or R). Add .DS_Store exclusions to the .gitignore</li> <li>Populate the README.md in the directory root with a short (few sentences) description of the overall purpose of the project. Over time, explanations of the analysis components will be added to this file.</li> </ul>"},{"location":"git-repo/#repository-structure","title":"Repository structure","text":"<p>Each repository should have one or more 'analysis module' directories in the root. A common set of modules for a simple project could be <code>00.data_download_exploration/</code>, <code>01.analysis_pipeline/</code>, and <code>02.downstream_analysis/</code>. Within each module will be the following sub-directories:</p> <ul> <li><code>inputs/</code>: any input data files that were retrieved from external sources</li> <li><code>analysis/</code>: scripts and notebooks used to process and analyse the data</li> <li><code>outputs/</code>: intermediate data and results tables (ie. norm_filtered.parquet or perturbation_stats.csv)</li> <li><code>figures/</code>: figures produced by the analysis scripts</li> <li><code>install_env.sh</code>: bash script for installing and activating the Python or R environment</li> <li><code>requirements.txt</code>: list of dependencies (package name and version) for the environment</li> </ul> <p>Files in the analysis folder should be numbered based on the order in which they should be executed (ie. 00.download_data.py, 01.descripe_exp_design.py, 02.filter_normalize.py, etc). You'll notice that there is a separate environment for each analysis module. This helps keeps environments more lightweight, hopefully reducing dependency conflicts across the entire repository.</p>"},{"location":"git-repo/#repository-as-a-lab-notebook","title":"Repository as a lab notebook","text":"<p>If you encounter an issue with the data, an open question that needs discussion, or generate cool results, please describe these in GitHub issues within the repository and tag Jess or other team members instead of sending an email. This keeps a clear record of all project-related troubleshooting, questions, and milestones. This is very helfpul for onboarding new team members to help out with the project, or for reminding ourselves of the reasons why particular decisions were made - this becomes very important for multi-year projects! The only exceptions are discussions that require confidentiality (use email) or quick reminder-type questions (use Slack). Keep in mind that most repositories will be made public eventually, including all associated GitHub Issues, so this is extra motiviation to keep things professional.</p>"},{"location":"git-repo/#nextflow","title":"NextFlow","text":"<p>The bulk of your analysis will likely by in the <code>xx.analysis_pipeline</code> module. Ideally it will be implemented using NextFlow. Pipeline orchestration software like NextFlow or Snakemake have a bit of a learning curve, but make running complex pipelines, reproducing them, and experimenting with different parameters or steps much, much, much easier in the long run. We chose NextFlow because this software is officially supported by EBI IT, so there are dedicated training sessions and lots of institutional knowledge on how to make it work well with the EBI cluster.</p>"},{"location":"git-repo/#general-principles","title":"General principles","text":"<ul> <li>Only use relative paths (ie. \"../inputs/counts.tsv\", not \"Users/jewald/project_repo/00.data_exploration/inputs/counts.tsv\").</li> <li>If changing analysis parameters from their default, give them a name and define them at the top of the script or notebook (ie. <code>corr_threshold = 0.8</code>).</li> <li>Enforce linear progression through modules and through scripts within modules - a module or script should never depend on results produced by a module or script with a higher number. Strictly adhering to this organisation makes it easier for new people (or future you, during paper revisions) to understand what was done.</li> <li>Do not read in the same input data multiple times per script - this is usually an indication that you should split the analysis into two parts and start another script.</li> <li>Do not mix analysis inputs and outputs - the input folder should be reserved for external inputs. Intermediate results should be written to the outputs folder. Take care to give your outputs sensible names so that it's relatively easy for an outsider to guess the contents of the files.</li> <li>Only very small input tables should be committed to the GitHub repo. For larger input files, include a download_XXX.sh file that fetches the data from an online repository or use symlinks to an external storage location on the cluster. If downloading data from online, download to a subdirectory in the inputs dir (ie. inputs/raw_profiles/) and add the subdir to the .gitignore.</li> <li>If using Jupyter notebooks, avoid committing printed out dataframes or variables, unless it is a highly meaningful result. For example print(df) is usually not helpful, but print(f\"There were {num_sig} significant perturbations\") could be a useful reference.</li> </ul>"},{"location":"join-lab/","title":"Joining the lab","text":"<p>We welcome inquiries from students and researchers at all levels who are passionate about the intersection of computational biology and environmental toxicology. If you\u2019re interested in joining the lab, please email Jess at jewald@ebi.ac.uk with a brief statement of your interests and your CV.</p> <p>We will always post new positions on LinkedIn, BlueSky, and the lab website, so you are encouraged to follow Jess on those platforms. If you are able to bring some of your own funding or plan to apply for a fellowship, please indicate this in your initial email. We are always willing to support fellowship applications when there is a good fit between the person, the project, and our lab!</p> <p>Please see below for more details depending on your circumstances.</p>"},{"location":"join-lab/#interns","title":"Interns","text":"<p>Internships are usually for senior undergraduate (3rd or 4th year) or Masters students. Most internships should be for 6 months or more; only in exceptional circumstances would we consider a 3-4 month internship as it usually takes several months before new lab members are familiar enough with our data and methods to make meaningful progress in their project. We will not host unpaid or remote internships.</p>"},{"location":"join-lab/#phd-candidates","title":"PhD candidates","text":"<p>PhD students are recruited via the EMBL International PhD Programme, and receive their degrees through the University of Cambridge. For queries regarding the programme, please contact the EBI Research Office (roffice@ebi.ac.uk). The next recruitment round opens September 2025, for a start date of Fall 2026. The application process is jointly conducted across all EMBL sites and labs. To ensure that your application reaches my eyes, please indicate my name and the EBI UK site in the application questions that ask about specific Group Leaders and locations. Please also highlight any courses or research experience that you have related to machine learning, omics data analysis, image analysis, and/or toxicology.</p>"},{"location":"join-lab/#postdocs","title":"Postdocs","text":"<p>I am always interested in supporting postdoctoral fellowship applications - if you've identified a fellowship that fits with your timelines, please give those details in your introductory email. There are some EMBL-specific postdoctoral fellowships that you can consider. Please contact me well in advance of the application deadlines (several months at least) so that I can provide adequate support during the writing process, and so that we have time to sort out any potential administrative details related to hosting your fellowship at EMBL.</p>"},{"location":"onboarding/","title":"Onboarding","text":""},{"location":"onboarding/#first-day","title":"First day","text":"<p>On the first day, you should:</p> <ul> <li>Get your temporary access badge from security.</li> <li>Basic IT: pick up your EBI laptop, connect to the EBI network and sign into your email account.</li> <li>Choose a desk and set up your keyboard and mouse.</li> </ul>"},{"location":"onboarding/#first-week","title":"First week","text":"<p>Within the first week, you should:</p> <ul> <li>Add your contact and logistical details to the lab contact spreadsheet. Access is restricted to lab members, so you will likely need to request access. We use this in the case of emergencies, to record dietary preferences for lab events, and to coordinate birthday treats!</li> <li>Complete the health &amp; safety courses available through Workday.</li> <li>Request access to the Codon Cluster using the link in this article.</li> <li>Ask Jess to add you to the Ewald Lab GitHub organisation. Send her your GitHub handle in the request. If you don't have one, create a GitHub account with a personal email so that your access remains after leaving EBI.</li> <li>Read through the Github guidelines and Tech strategy pages of the handbook. Write down anything that is confusing or unfamiliar to you - you can go through it with Jess during your first 1:1 and she can suggest resources for learning them.</li> </ul>"},{"location":"onboarding/#first-month","title":"First month","text":"<ul> <li>Run through the example image-based profiling pipeline tutorial</li> <li>Run through the basic CellProfiler for Cell Painting tutorial on the Codon Cluster using an interactive HPC session</li> </ul>"},{"location":"reading/reading-overview/","title":"Reading overview","text":"<p>This page is a collection of important and inspiring papers in the various fields that the Ewald Lab works in. Our group uses cell profiling to understand what compounds do to cells, with a long-term goal of developing new computational methods that predict in vivo toxicity from in vitro exposures (Section 1) . While we are interested in using all forms of cell profiling (transcriptomic, metabolomic, etc), our expertise in image-based cell profiling differentiates us from other groups in the same space (Section 2). Our work has applications in both regulatory toxicology (protecting humans and ecosystems from unintended chemical exposures, Section 3) and pharmaceutical toxicology (assessing the safety of compounds that are designed to perturb human biology, Section 4). Beyond direct applications of cell profiling to toxicology, we are also interested in pushing the boundaries of the types of information that can be detected / extracted from images of cells (Section 5). Our work in this area is sometimes more towards fundamental single-cell biology (Section 6).</p> <p>All Ewald Lab members should have familiarity with the conceptual/review papers in section 1 and 2, as these provide the foundation for the big picture that the lab is working towards. Each individual member will likely focus their research on one of sections 3-6, with work that is more application (3 &amp; 4), methods (5), or basic research (6) focused. </p>"}]}